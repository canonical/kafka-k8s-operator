groups:
- name: kafka_general
  rules:

  - alert: KafkaJmxExporterMissing
    expr: up == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Prometheus target missing ({{$labels.juju_unit}} {{ $labels.instance }})"
      description: "Prometheus target has disappeared for 5 minutes. This indicates the exporter serving at {{ $labels.instance }} might be crashed.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"


- name: kafka_jvm
  rules:

  - alert: KafkaJvmMemoryNearFull
    expr: (sum by (juju_unit)(jvm_memory_bytes_used) / sum by (juju_unit)(jvm_memory_bytes_max)) * 100 > 85
    for: 5m
    labels:
        severity: warning
    annotations:
        summary: "JVM memory is nearly full ({{ $labels.juju_unit }})"
        description: "JVM memory usage is more than 85% for 5 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: KafkaJvmThreadsDeadLocked
    expr: jvm_threads_deadlocked > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "Kafka JVM threads Deadlock occurred ({{ $labels.juju_unit }})"
      description: "JVM Thread Deadlock means a situation where two or more JVM threads are blocked forever, waiting for each other. Deadlock occurs when multiple threads need the same locks but obtain them in different order. Also look to JVM documentation about threads state: https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Thread.State.html\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"


- name: kafka_broker_and_controller
  rules:

  - alert: NoOnlineBrokers
    expr: count(kafka_server_kafkaserver_brokerstate) by (instance) == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "No online brokers in the cluster"
      description: "The online broker count is 0 in the cluster for 5 minutes."

  - alert: NoActiveControllers
    expr: sum(kafka_controller_kafkacontroller_activecontrollercount) == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "No active controllers in the cluster"
      description: "No broker in the cluster is reporting as the active controller for 5 minutes. During steady state there should be only one active controller per cluster."

  - alert: UncleanLeaderElectionRateAbnormal
    expr: max by (juju_unit) (rate(kafka_controller_controllerstats_uncleanleaderelections_total[5m])) != 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Unclean leader election rate reported by '{{ $labels.juju_unit }}' is abnormal ({{ $value }})"
      description: "Controller or broler ({{ $labels.juju_unit }}) reported {{ $value }} unclean partition leader elections in the past 5 minutes and lasted for 5 minute. When unclean leader election is held among out-of-sync replicas, there is a possibility of data loss if any messages were not synced prior to the loss of the former leader. So if the number of unclean elections is greater than 0, investigate broker logs to determine why leaders were re-elected, and look for WARN or ERROR messages. Consider setting the broker configuration parameter unclean.leader.election.enable to false so that a replica outside of the set of in-sync replicas is never elected leader."


- name: kafka_partitions_and_replicas
  rules:

  - alert: PartitionsOffline
    expr: sum(kafka_controller_kafkacontroller_offlinepartitionscount) > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "{{ $value }} partitions are offline"
      description: "{{ $value }} partitions are offline for 5 minutes. After successful leader election, if the leader for partition dies, then the partition moves to the OfflinePartition state. Offline partitions are not available for reading and writing. Restart the brokers, if needed, and check the logs for errors."

  - alert: PartitionsCountHigh
    expr: sum by (juju_unit) (kafka_server_replicamanager_partitioncount) > 4000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has too many partitions ({{ $value }})"
      description: "There are too many partitions ({{ $value }}) in broker '{{ $labels.juju_unit }}'. Recommended number of partition per broker should be below 4000. Increase the number of broker and rebalance partitions in order to keep this number controlled."

  - alert: PartitionsUnderReplicated
    expr: sum by (juju_unit) (kafka_server_replicamanager_underreplicatedpartitions) > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has {{ $value }} partitions are under replicated"
      description: "There are too many partitions are under replicated in broker '{{ $labels.juju_unit }}' for 5 minutes. Under-replicated partitions means that one or more replicas are not available. This is usually because a broker is down.  Restart the broker, and check for errors in the logs."

  - alert: ReplicaFetcherManagerMaxLagTooLarge
    expr: avg by (juju_unit) (kafka_server_replicafetchermanager_maxlag) > 50
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has replica fetcher manager max lag is too large"
      description: "The maximum lag ({{ $value }}) between the time that messages are received by the leader replica and by the follower replicas is larger than 50."

  - alert: TopicsNotReplicated
    expr: count by (topic, partition) (kafka_cluster_partition_insyncreplicascount) <= 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Topic '{{ $labels.topic }}' in partition {{ $labels.partition }} is not replicated"
      description: "The ISR for topic '{{ $labels.topic }}' in partition {{ $labels.partition }} is less than or equal to 1. The topic is subject to data loss if the partition goes down and data cannot be recovered."


- name: kafka_in_sync_replicas
  rules:

  - alert: ISRExpandsRateAbnormal
    expr: max by (juju_unit) (rate(kafka_server_replicamanager_isrexpands_total[5m])) != 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has abnormal ISR expansion rate"
      description: "Broker '{{ $labels.juju_unit }}' has ISR expansion rate not equal to 0 ({{ $value }}) in the past 5 minutes and last 5 minutes. If a broker goes down, ISR for some of the partitions shrink. When that broker is up again, ISRs are expanded once the replicas are fully caught up. Other than that, the expected value for ISR expansion rate is 0. If ISR is expanding and shrinking frequently, adjust Allowed replica lag."

  - alert: ISRShrinksRateAbnormal
    expr: max by (juju_unit) (rate(kafka_server_replicamanager_isrshrinks_total[5m])) != 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has abnormal ISR shrinking rate"
      description: "Broker '{{ $labels.juju_unit }}' has ISR shrink rate not equal to 0 ({{ $value }}) in the past 5 minutes and lasted to 5 minutes. If a broker goes down, ISR for some of the partitions shrink. When that broker is up again, ISRs are expanded once the replicas are fully caught up. Other than that, the expected value for ISR shrink rate is 0. If ISR is expanding and shrinking frequently, adjust Allowed replica lag."



- name: kafka_network
  rules:

  - alert: NetworkProcessorTooBusy
    expr: (1 - sum by (juju_unit) (kafka_network_socketserver_networkprocessoravgidlepercent)) * 100 >= 70
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has high network processor usage ({{ $value }}%)"
      description: "Broker '{{ $labels.juju_unit }}' has high network processor usage ({{ $value }}%) for 5 minutes. The average usage of the network processors. A higher value indicates that the network workload of the broker is very high."

  - alert: RequestHandlerTooBusy
    expr: (1 - sum by (juju_unit) (kafka_server_kafkarequesthandlerpool_requesthandleravgidle_percent)) * 100 >= 70
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has high request handler usage ({{ $value }}%)"
      description: "Broker '{{ $labels.juju_unit }}' has high request handler usage ({{ $value }}%) for 5 minutes. The average usage of request handler threads (IO). A higher value indicates that the workload of a broker is very high."

  - alert: RequestQueueTimeMaxTooHigh
    expr: max by (juju_unit) (kafka_network_requestmetrics_requestqueuetimems{quantile="0.95"}) > 200
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has high maximum request queue time ({{ $value }}ms)"
      description: "The 95 percentile of the maximum request queue time exceeded 200ms for a request ({{ $value }}ms) and lasted for 5 minutes."

  - alert: ResponseQueueTimeMaxTooHigh
    expr: max by (juju_unit) (kafka_network_requestmetrics_responsequeuetimems{quantile="0.95"}) > 200
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has high maximum response queue time ({{ $value }}ms)"
      description: "The 95 percentile of the maximum response queue time exceeded 200ms for a request ({{ $value }}ms) and lasted for 5 minutes"

  - alert: RecordsLagMaxTooLarge
    expr: sum by (juju_unit, clientId) (kafka_server_fetcherlagmetrics_consumerlag) > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has large records lag"
      description: "The maximum lag in terms of number of records for any partition in this window is too large for 5 minutes(client={{ $labels.clientId}}, lag={{ $value }}). An increasing value over time is your best indication that the consumer group is not keeping up with the producers."


- name: kafka_topics_and_logs
  rules:

  - alert: OfflineLogDirectoryExists
    expr: sum by (juju_unit) (kafka_log_logmanager_offlinelogdirectorycount) > 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' has {{ $value }} offline log directories"
      description: "There are {{ $value }} offline log directories on {{ $labels.juju_unit }} for 5 minutes."

  - alert: TopicCountTooHigh
    expr: max by (juju_unit) (kafka_controller_kafkacontroller_globaltopiccount) >= 1000
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "Broker '{{ $labels.juju_unit }}' reaches 1000 topics"
      description: "The number of active topics in the cluster has reached 1000."
