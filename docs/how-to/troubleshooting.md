# Troubleshooting guide

This page goes over some recommended tools and approaches to troubleshooting the charm.

## Check model's status

The first step of any troubleshooting should always be analysing the `juju status` command output:

```bash
juju status --storage --integrations
```

In the command above:

* `--storage` -- to include storage information into the output
* `--integrations` -- to include relations/integrations information into the output

```{note}
Learn more: 

* `juju status` command [reference](https://documentation.ubuntu.com/juju/3.6/reference/juju-cli/list-of-juju-cli-commands/status/)
* [List of charm's error messages](reference-statuses)
```

## Check logs

Log messages can provide more information, than `juju status`, especially on dynamic or fast-paced processes.
Logs are written inside machines, operated by Juju. You can access them directly, via Juju client, or via [Canonical Observability Stack](https://documentation.ubuntu.com/observability/).

### Juju client

Check for logs via Juju:

```bash
juju debug-log --replay --tail
```

You can increase verbosity level if needed:

```bash
juju model-config 'logging-config=<root>=INFO;unit=DEBUG'
```

```{note}
Learn more:

* `juju debug-log` command [reference](https://documentation.ubuntu.com/juju/3.6/reference/juju-cli/list-of-juju-cli-commands/debug-log/)
* [How to manage logs](https://documentation.ubuntu.com/juju/3.6/howto/manage-logs/) in Juju.
```

### Direct access

Workload logs are stored on units and can be accessed in the following directories:

* Apache Kafka -- `/var/log/kafka/`
* Apache ZooKeeper -- `/var/log/zookeeper/`

Use `juju ssh` command to connect to a unit and access logs directly, for example:

```shell
juju ssh --container kafka <unit-name> 'tail -f /var/log/kafka/server.log'
```

Some of the most useful log files for Apache Kafka:

* `server.log` -- The actual service logs.
* `kafka-authorizer.log` -- Failed SASL authentications + denied ACL operations.
* `controller.log` -- Logs from the {spellexception}`KafkaController`.
* `kafkaServer-gc.log` -- Apache Kafka's Java garbage collector log.
* `state-change.log` -- Tracks partition leader re-elections log.

<!-- TODO: Consider moving the log files list to either the Reference or Explanation section -->

```{note}
Learn more: 

* Charmed Apache Kafka K8s [file system paths reference](reference-file-system-paths).
* `juju ssh` command [reference](https://documentation.ubuntu.com/juju/3.6/reference/juju-cli/list-of-juju-cli-commands/ssh/)
```

### COS

Canonical Observability Stack (COS) gathers, processes, visualises, and alerts on telemetry generated by workloads.
In COS, Grafana Loki is the storage and querying backend for logs.
You can [query Loki](https://discourse.charmhub.io/t/loki-k8s-docs-http-api/13440) to obtain logs via [HTTP API](https://grafana.com/docs/loki/latest/reference/loki-http-api/#query-logs-within-a-range-of-time) or [visualise logs in Loki in Grafana](https://grafana.com/docs/grafana/latest/datasources/loki/) and use [LogQL](https://grafana.com/docs/loki/latest/query/) - a log query language.

```{note}
Learn more:

* COS [Logging architecture explanation](https://documentation.ubuntu.com/observability/explanation/logging-architecture/)
* [How to enable monitoring using COS](how-to-monitoring-enable-monitoring) guide
```

## Partition rebalancing

```{warning}
Scaling a Charmed Apache Kafka K8s cluster does not automatically rebalance existing topics and partitions. Rebalancing must be performed manuallyâ€”before scaling in or after scaling out.
```

See the [Partition reassignment](how-to-partitions-reassignment) section of the How-to manage units guide for details on how to rebalance Apache Kafka partitions between units.

## Run out of disk space

At this moment, Juju does not support increasing the size of a storage in a Juju application.
If you encounter a problem with size limit of existing storage, consider adding a new storage or redeploying the charm with a bigger storage.

## Sizing guide

We recommend the following minimum configuration for production environments:

* For a single region/AZ deployment:
  * `3` units of Apache Kafka
  * `3` units of Apache ZooKeeper
* For a multi-region/AZ deployment:
  * `3` units of Apache Kafka
  * `5` units of Apache ZooKeeper

For very high numbers of topics, partitions and brokers, consider scaling the Apache ZooKeeper cluster out to `5` or up to `7` units.
For brokers, start with a minimum estimated number of Charmed Apache Kafka K8s units, scaling out the number of units to meet desired throughput.

```{warning}
Scaling an Apache ZooKeeper cluster out to higher numbers does not provide linear growth in performance.
Due to cross communication overhead, there is a point, after which, more nodes means less performance.
There is no specific algorithm to calculate optimal numbers, as they are dependant on multiple parameters, including workload characteristics.
```

```{note}
Learn more:

* Apache ZooKeeper [High availability explanation](https://canonical-zookeeper.readthedocs-hosted.com/content/explanation/ha/) page for quorum calculation.
```

## Contact us

If you encountered an undocumented or unexpected behaviour of the Charmed Apache Kafka K8s, feel free to create an [issue on GitHub](https://github.com/canonical/kafka-operator/issues) or contact us directly.
See the (reference-contact) page for contact details.
